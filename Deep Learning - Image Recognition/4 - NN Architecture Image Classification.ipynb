{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90be4ef4-1593-4520-aaa2-e5e7b17fa887",
   "metadata": {},
   "source": [
    "# Neural Network Image Classification Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d6c8b0-345f-4743-b2c8-1a48e5425ff4",
   "metadata": {},
   "source": [
    "*The information described below details the structure of the neural network specifically made for the purpose of image classification:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536b3f75-d029-419d-abca-c9e851f51184",
   "metadata": {},
   "source": [
    "## Input Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f05dd9-bdad-47f1-9e07-b8445f2cf85f",
   "metadata": {},
   "source": [
    "The input layer is responsible for receiving the raw image as input of the neural network. It ensures that the image data is in a suitable format for efficient and effective processing in the subsequent layers of our neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70ac011-eff2-44c9-a509-76eed2d089f4",
   "metadata": {},
   "source": [
    "In the input layer, the image is represented as a grid of pixels with individual pixels containing numerical values ranging from 0 to 255. These values represent the intensity of the color; with a vector of 3 numbers for 3 - channel images (RGB) and a single value for grayscale images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dc3715-10d6-47de-bec7-b0e5ff41426d",
   "metadata": {},
   "source": [
    "The input layer may receive either a 2-dimensional tensor or a 3-dimensional tensor depending on the nature of input data it receives. For cases where we use a colored image, it receives a 3 - dimensional tensor of height, width, and 3-channel values. On the other hand if it recieves a grayscale image, then it only requires a 2 - dimensional tensor for height and width."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff22e9f2-91b7-4160-a535-a83f88ea3df9",
   "metadata": {},
   "source": [
    "Note that before our images are fed to the neural network for training, they are preprocessed to a suitable image format. This includes resizing them to a consistent size, normalizing the pixel values, and may also include data augmentation such as rotation to increase the diversity of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1d13dd-18e0-4ff5-8277-79e5cdb76542",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
