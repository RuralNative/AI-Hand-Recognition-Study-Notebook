{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07436161-db56-4d31-a7cc-808afbb6a975",
   "metadata": {},
   "source": [
    "## Library Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da62ac65-d2e8-427e-9e4a-181cb54986ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary Python modules\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, MaxPool2D, Conv2D, Flatten\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5034c930-2f88-4088-8c6f-28394bf02fe1",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f57295-0c63-4cf7-80df-1ae4880df826",
   "metadata": {},
   "source": [
    "**Normalization of Image Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276636aa-0482-477c-8940-ea8e736a4f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1/255, \n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.1,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    validation_split = 0.2)\n",
    "test_datagen = ImageDataGenerator(rescale = 1/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7b87cc-aa44-455b-9554-df1b2e9dd0b1",
   "metadata": {},
   "source": [
    "**Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfddd9f-9b8d-4ddf-8b3c-63c49f7e9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes for images\n",
    "asl_classes = ['A','B','C','D','E','F','G','H','I','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y']\n",
    "\n",
    "# Directory Values\n",
    "train_data_directory = \"/kaggle/input/handsignimages/Train\"\n",
    "test_data_directory = \"/kaggle/input/handsignimages/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a2f816-e970-4109-adf0-499c2d70ca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from dataset\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_directory,\n",
    "    target_size = (28,28),\n",
    "    classes = asl_classes,\n",
    "    class_mode = 'sparse',\n",
    "    color_mode = 'rgb',\n",
    "    subset = 'training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_data_directory,\n",
    "    target_size = (28,28),\n",
    "    classes = asl_classes,\n",
    "    class_mode = 'sparse',\n",
    "    color_mode = 'rgb',\n",
    "    subset = 'validation'\n",
    ")\n",
    "\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "    test_data_directory,\n",
    "    target_size = (28,28),\n",
    "    classes = asl_classes,\n",
    "    class_mode = 'sparse',\n",
    "    color_mode = 'rgb'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a168a6-e9ac-46e7-b1ad-86c928e884fa",
   "metadata": {},
   "source": [
    "## CNN Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1781f91-2867-428c-905a-85c8cd0768ef",
   "metadata": {},
   "source": [
    "**Create Model Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3648ee-5a82-4e11-aa24-5410b5aefdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base model\n",
    "model = Sequential()\n",
    "\n",
    "# Add first convolutional layer\n",
    "model.add(Conv2D(128, (3,3), activation = \"relu\", input_shape=(28, 28, 1)))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Add second convolutional layer\n",
    "model.add(Conv2D(128, (3,3), activation = \"relu\"))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Flatten convolutional output data\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add fully-connected layer\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "\n",
    "# Add output layer\n",
    "model.add(Dense(24, activation = \"softmax\"))\n",
    "\n",
    "# Provide model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b1daad-1ceb-45e9-a9c3-f485c1a8e275",
   "metadata": {},
   "source": [
    "**Use RMSprop as Optimizer with SCC for Loss Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e71896-e531-4561-a3d1-7b3a730ae41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = RMSprop(lr = 0.001),\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb3dd54-538f-4fe7-bfc8-e5f2de9036d4",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314ecbbd-e18a-4004-afda-1f1b6ffef241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model with given architecture\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data = validation_generator\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
