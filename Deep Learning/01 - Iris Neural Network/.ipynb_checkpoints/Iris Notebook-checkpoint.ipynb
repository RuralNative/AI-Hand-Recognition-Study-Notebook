{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b9cc808",
   "metadata": {},
   "source": [
    "# Iris\n",
    "\n",
    "This examples demonstrates the core deep learning model building concepts using the Keras library. The Iris flower dataset is used to build the model and perform classification tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fabf059",
   "metadata": {},
   "source": [
    "## 4.2. Prepare Input Data for Deep Learning\n",
    "\n",
    "Prepare and preprocess our input data to convert into something our neural network can read and access.\n",
    "\n",
    "1. Load data into a Pandas DataFrame\n",
    "2. Preprocess the categorical target variables\n",
    "3. Convert the DataFrame to a Numpy array\n",
    "4. Scale the feature dataset\n",
    "5. Use one-hot-encoding for the target variable\n",
    "6. Split into training and test datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "453f74bc-b0f8-4e74-8a7d-7fa4aee5918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary Python libraries for our model training\n",
    "import os\n",
    "import pandas as pandas\n",
    "import tensorflow as tensorflow\n",
    "import numpy as numpy\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75b8eec5-8e46-4d0e-874f-cb780115bd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Sepal.Length  150 non-null    float64\n",
      " 1   Sepal.Width   150 non-null    float64\n",
      " 2   Petal.Length  150 non-null    float64\n",
      " 3   Petal.Width   150 non-null    float64\n",
      " 4   Species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load data from our CSV file into a Pandas DataFrame\n",
    "iris_data = pandas.read_csv('iris.csv')\n",
    "iris_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60491464-8a1d-4fa3-acc4-ecb411264534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess categorical target variable into numeric values\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "iris_data['Species'] = label_encoder.fit_transform(iris_data['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a4dbb32-84e7-4296-b3e9-d9d6d49fada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame into Numpy Array/s\n",
    "numpy_iris = iris_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15da1cec-5183-4a33-8e26-a8a1db6a76d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the feature dataset\n",
    "\n",
    "## Separate feature variables from the target variable\n",
    "x_data = numpy_iris[:,0:4]\n",
    "y_data = numpy_iris[:,4]\n",
    "\n",
    "## Create and train Scaler model fit for the given input data\n",
    "scaler_model = StandardScaler().fit(x_data)\n",
    "\n",
    "## Scale numeric feature variables\n",
    "x_data = scaler_model.transform(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c05fba9b-2e02-4028-bab2-5d898a752c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one-hot encoding for categorical target variables\n",
    "y_data = tensorflow.keras.utils.to_categorical(y_data,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "709a9da8-3f8e-4521-9ebf-6556237601a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing data\n",
    "x_data, x_test, y_data, y_test = train_test_split(x_data, y_data, test_size=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df744ea0-2cf3-44a8-bcc6-f49765e2886d",
   "metadata": {},
   "source": [
    "## Creating a Model\n",
    "\n",
    "Creating a model in Keras requires defining the following\n",
    "\n",
    "1. Number of hidden layers\n",
    "2. Number of nodes in each layer\n",
    "3. Activation functions\n",
    "4. Loss Function & Accuracy measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bb09cd1-ebcf-464f-9664-28d6cc88538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e50e604-fe10-4149-86d2-d50e5e883d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden-layer-1 (Dense)      (None, 128)               640       \n",
      "                                                                 \n",
      " hidden-layer-2 (Dense)      (None, 128)               16512     \n",
      "                                                                 \n",
      " output-layer (Dense)        (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,539\n",
      "Trainable params: 17,539\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Number of classes for our target variable\n",
    "target_classes = 3\n",
    "\n",
    "# Create a Sequential Model\n",
    "model = tensorflow.keras.models.Sequential()\n",
    "\n",
    "# Add first hidden layer\n",
    "model.add(keras.layers.Dense(128,\n",
    "                             input_shape = (4,),\n",
    "                             name = \"hidden-layer-1\",\n",
    "                             activation = 'relu'))\n",
    "\n",
    "# Add second hidden layer\n",
    "model.add(keras.layers.Dense(128,\n",
    "                             name = \"hidden-layer-2\",\n",
    "                             activation = 'relu'))\n",
    "\n",
    "# Add output layer with softmax activation function\n",
    "model.add(keras.layers.Dense(target_classes,\n",
    "                             name = \"output-layer\",\n",
    "                             activation = 'softmax'))\n",
    "\n",
    "# Compile the model with loss function and metrics\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# Print compiled model meta-data\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7317266c-ef90-4cdb-a046-5c264b1bb9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e46252-c987-40e4-a521-35bf944844e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
