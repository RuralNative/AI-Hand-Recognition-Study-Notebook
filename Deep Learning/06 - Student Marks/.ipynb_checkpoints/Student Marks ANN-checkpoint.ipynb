{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b5ebbde-1b5a-4e9b-965c-55bba1de8744",
   "metadata": {},
   "source": [
    "# Student Marks Neural Network\n",
    "*This Jupyter notebook details the construction of a neural network that predicts the math score of a student based from their demographic profile and reading/writing grades.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9374a4ac-15c4-495c-bf38-58df469c3df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries/modules\n",
    "import os\n",
    "import pandas as pandas\n",
    "import tensorflow as tensorflow\n",
    "from tensorflow import keras\n",
    "import numpy as numpy\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6b4a1a-f752-46df-8252-80454453358e",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a4f66a6-59ec-4e69-a096-936bae5bc633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   gender                       1000 non-null   object\n",
      " 1   race/ethnicity               1000 non-null   object\n",
      " 2   parental level of education  1000 non-null   object\n",
      " 3   lunch                        1000 non-null   object\n",
      " 4   test preparation course      1000 non-null   object\n",
      " 5   math score                   1000 non-null   int64 \n",
      " 6   reading score                1000 non-null   int64 \n",
      " 7   writing score                1000 non-null   int64 \n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 62.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load Data from CSV file\n",
    "student_data = pandas.read_csv('exams.csv')\n",
    "student_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc0cf119-3f7d-4979-b529-51c3caedb6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace space characters with underscore, simplified race/ethnicity name\n",
    "student_data.columns = student_data.columns.str.replace(' ', '_')\n",
    "student_data.columns = student_data.columns.str.replace('race/', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9f468a00-81b8-4f50-86dc-0b53c9cc92c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                       Non-Null Count  Dtype\n",
      "---  ------                       --------------  -----\n",
      " 0   gender                       1000 non-null   int64\n",
      " 1   ethnicity                    1000 non-null   int64\n",
      " 2   parental_level_of_education  1000 non-null   int64\n",
      " 3   lunch                        1000 non-null   int64\n",
      " 4   test_preparation_course      1000 non-null   int64\n",
      " 5   math_score                   1000 non-null   int64\n",
      " 6   reading_score                1000 non-null   int64\n",
      " 7   writing_score                1000 non-null   int64\n",
      "dtypes: int64(8)\n",
      "memory usage: 62.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Preprocess categorical data to convert it into numerical values\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "categorical_columns = ['gender', 'ethnicity', 'parental_level_of_education', 'lunch', 'test_preparation_course']\n",
    "for column in categorical_columns:\n",
    "    student_data[column] = label_encoder.fit_transform(student_data[column])\n",
    "student_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98e377e5-252a-49ca-aa56-a0b9bbe77931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame into Numpy Array\n",
    "student_numpy = student_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "81e03ea7-c982-4711-b7d4-f0a8a58f1f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating feature variables from target variable\n",
    "x_data = numpy.concatenate((student_numpy[:,0:4], student_numpy[:,6:7]), axis = 1)\n",
    "y_data = student_numpy[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c0ab8dd3-0299-4a07-900b-549a63fa6fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Scaler Model and use it for scaling data\n",
    "scaler_model = StandardScaler().fit(x_data)\n",
    "x_data = scaler_model.transform(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6780b769-1cea-449e-bc5b-abcf7d6c044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35609b8-ce4f-424a-a2e9-71901dc31217",
   "metadata": {},
   "source": [
    "## Creating a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "319e3e32-8777-4f15-9aa5-3deed21642ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Hidden_Layer_1 (Dense)      (None, 128)               1024      \n",
      "                                                                 \n",
      " Hidden_Layer_2 (Dense)      (None, 128)               16512     \n",
      "                                                                 \n",
      " Output_Layer (Dense)        (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,665\n",
      "Trainable params: 17,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "target_output = 1\n",
    "\n",
    "# Instantiate Sequential model\n",
    "model = tensorflow.keras.models.Sequential()\n",
    "\n",
    "# Add hidden layers\n",
    "model.add(keras.layers.Dense(128,\n",
    "                             input_shape = (7,),\n",
    "                             name = \"Hidden_Layer_1\",\n",
    "                             activation = 'relu'))\n",
    "model.add(keras.layers.Dense(128,\n",
    "                             name = \"Hidden_Layer_2\",\n",
    "                             activation = 'relu'))\n",
    "\n",
    "# Add output layer\n",
    "model.add(keras.layers.Dense(target_output,\n",
    "                             name = \"Output_Layer\",\n",
    "                             activation = 'linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss = 'mean_squared_error',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffb017f-ce15-4c24-9062-e3fc70cf6e43",
   "metadata": {},
   "source": [
    "## Training and Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6067f145-1895-4ee2-b104-bb774626184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for Training/Evaluation\n",
    "VERBOSE = 1\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "# Train model with hyperparameters\n",
    "print(\"Training Progress:\\n-----------------------------\")\n",
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    batch_size = BATCH_SIZE,\n",
    "                    epochs = EPOCHS,\n",
    "                    verbose = VERBOSE,\n",
    "                    validation_split = VALIDATION_SPLIT)\n",
    "\n",
    "print(\"\\nAccuracy during Training :\\n------------------------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
