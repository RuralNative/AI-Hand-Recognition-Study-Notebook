{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07436161-db56-4d31-a7cc-808afbb6a975",
   "metadata": {},
   "source": [
    "## Library Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da62ac65-d2e8-427e-9e4a-181cb54986ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary Python modules\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, MaxPool2D, Conv2D, Flatten\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5034c930-2f88-4088-8c6f-28394bf02fe1",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f57295-0c63-4cf7-80df-1ae4880df826",
   "metadata": {},
   "source": [
    "**Normalization of Image Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276636aa-0482-477c-8940-ea8e736a4f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1/255, \n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.1,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    validation_split = 0.2)\n",
    "test_datagen = ImageDataGenerator(rescale = 1/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7b87cc-aa44-455b-9554-df1b2e9dd0b1",
   "metadata": {},
   "source": [
    "**Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfddd9f-9b8d-4ddf-8b3c-63c49f7e9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes for images\n",
    "asl_classes = ['A','B','C','D','E','F','G','H','I','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y']\n",
    "\n",
    "# Directory Values\n",
    "train_data_directory = \"/kaggle/input/handsignimages/Train\"\n",
    "test_data_directory = \"/kaggle/input/handsignimages/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a2f816-e970-4109-adf0-499c2d70ca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from dataset\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_directory,\n",
    "    target_size = (28,28),\n",
    "    classes = asl_classes,\n",
    "    class_mode = 'sparse',\n",
    "    color_mode = 'rgb',\n",
    "    subset = 'training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_data_directory,\n",
    "    target_size = (28,28),\n",
    "    classes = asl_classes,\n",
    "    class_mode = 'sparse',\n",
    "    color_mode = 'rgb',\n",
    "    subset = 'validation'\n",
    ")\n",
    "\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "    test_data_directory,\n",
    "    target_size = (28,28),\n",
    "    classes = asl_classes,\n",
    "    class_mode = 'sparse',\n",
    "    color_mode = 'rgb'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a168a6-e9ac-46e7-b1ad-86c928e884fa",
   "metadata": {},
   "source": [
    "## CNN Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1781f91-2867-428c-905a-85c8cd0768ef",
   "metadata": {},
   "source": [
    "**Create Model Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3648ee-5a82-4e11-aa24-5410b5aefdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base model\n",
    "model = Sequential()\n",
    "\n",
    "# Add first convolutional layer\n",
    "model.add(Conv2D(128, (3,3), activation = \"relu\", input_shape=(28, 28, 1)))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Add second convolutional layer\n",
    "model.add(Conv2D(128, (3,3), activation = \"relu\"))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Flatten convolutional output data\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add fully-connected layer\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "\n",
    "# Add output layer\n",
    "model.add(Dense(24, activation = \"softmax\"))\n",
    "\n",
    "# Provide model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b1daad-1ceb-45e9-a9c3-f485c1a8e275",
   "metadata": {},
   "source": [
    "**Use RMSprop as Optimizer with SCC for Loss Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e71896-e531-4561-a3d1-7b3a730ae41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = RMSprop(lr = 0.001),\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb3dd54-538f-4fe7-bfc8-e5f2de9036d4",
   "metadata": {},
   "source": [
    "## Training\n",
    "**Train model with the provided architecture through 50 epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314ecbbd-e18a-4004-afda-1f1b6ffef241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model with given architecture\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data = validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c63701-ea76-49aa-82ea-4fb2a9849309",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "**Test the model with data it has not seen to check its performance against outside data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84983c3e-d589-4eee-a789-fc17d24b66bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d10013-5f4b-44d7-b60f-008bff5cca63",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e847aac-17fd-4c6e-bc3c-502006677b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT LOSS AND ACCURACY\n",
    "# %matplotlib inline\n",
    "\n",
    "import matplotlib.image  as mpimg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34755eeb-cd5a-4c7a-b4d5-f3407f365e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.figure()\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "\n",
    "\n",
    "plt.title('Training and validation loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef63a79-fdde-48a0-8d0e-fd0b210d8918",
   "metadata": {},
   "source": [
    "## Prediction\r\n",
    "**Randomly choose an alphabet from folder and display its prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d652f99-2cc9-420c-bfef-fc67fa23de16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import cv2 as cv\n",
    "\n",
    "def testModel(alphabet = \"A\"):\n",
    "    dirname, _, filenames = list(os.walk(f'/kaggle/input/handsignimages/Test/{alphabet.upper()}'))[0]\n",
    "    img_path = os.path.join(dirname, filenames[randint(0, len(filenames))])\n",
    "    print(img_path)\n",
    "    img = cv.imread(img_path, 0).reshape(1, 28, 28, 1)\n",
    "    pred = model.predict(img)\n",
    "    pred_label = asl_classes[np.argmax(pred)]\n",
    "\n",
    "    plt.title(pred_label)\n",
    "    plt.imshow(img[0,:,:,0], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654d6928-014e-47aa-871b-a5fda5e339d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "testModel(\"m\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
